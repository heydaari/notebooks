{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[],"dockerImageVersionId":31194,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops --quiet\n\n# Higher jax versions have some issue with Array abstrafication in Keras, we use the 0.7.2 for this tutorial \n!pip install jax==0.7.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:23:55.111678Z","iopub.execute_input":"2025-11-08T16:23:55.111974Z","iopub.status.idle":"2025-11-08T16:24:08.428986Z","shell.execute_reply.started":"2025-11-08T16:23:55.111954Z","shell.execute_reply":"2025-11-08T16:24:08.427902Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting jax==0.7.2\n  Downloading jax-0.7.2-py3-none-any.whl.metadata (13 kB)\nCollecting jaxlib<=0.7.2,>=0.7.2 (from jax==0.7.2)\n  Downloading jaxlib-0.7.2-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/site-packages (from jax==0.7.2) (0.5.3)\nRequirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/site-packages (from jax==0.7.2) (2.3.4)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.12/site-packages (from jax==0.7.2) (3.4.0)\nRequirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/site-packages (from jax==0.7.2) (1.16.3)\nDownloading jax-0.7.2-py3-none-any.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jaxlib-0.7.2-cp312-cp312-manylinux_2_27_x86_64.whl (78.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: jaxlib, jax\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.8.0\n    Uninstalling jaxlib-0.8.0:\n      Successfully uninstalled jaxlib-0.8.0\n  Attempting uninstall: jax\n    Found existing installation: jax 0.8.0\n    Uninstalling jax-0.8.0:\n      Successfully uninstalled jax-0.8.0\nSuccessfully installed jax-0.7.2 jaxlib-0.7.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ['KERAS_BACKEND'] = 'jax'\nos.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n\nimport jax\nimport jax.numpy as jnp\nfrom einops import rearrange\nfrom jax import jit, value_and_grad\nfrom torchvision.datasets import CIFAR10, Imagenette\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom jax import random\n\nimport keras\nfrom keras import ops\n\n# Vision Transformer hyper-parameters\nimage_size = 128\npatch_size = 4\nnum_patches = (image_size // patch_size) ** 2\n\nnum_layers = 4\nhidden_dim = 64\nmlp_dim = 128\n\n\nnum_classes = 10\nnum_heads = 4\nhead_dim = hidden_dim//num_heads","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:11.302150Z","iopub.execute_input":"2025-11-08T16:24:11.302403Z","iopub.status.idle":"2025-11-08T16:24:15.998012Z","shell.execute_reply.started":"2025-11-08T16:24:11.302381Z","shell.execute_reply":"2025-11-08T16:24:15.996944Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"vit_parameters = {\n    'patch_embed': None,\n    'positional_encoding': None,\n    'layers': [],\n    'final_layer_norm': None,\n    'head': [],\n    'cls_token': None\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:15.998939Z","iopub.execute_input":"2025-11-08T16:24:15.999277Z","iopub.status.idle":"2025-11-08T16:24:16.002344Z","shell.execute_reply.started":"2025-11-08T16:24:15.999259Z","shell.execute_reply":"2025-11-08T16:24:16.001492Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from keras import initializers\n\n# for the class token, we just need a single vector of the same size as a token\ncls_token = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (1, hidden_dim),\n        trainable=True,\n    )\nvit_parameters['cls_token'] = cls_token\n\n\npatch_embed = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = ((3 * patch_size * patch_size), hidden_dim),\n        trainable=True,\n    )\n\nvit_parameters['patch_embed'] = patch_embed\n\n\npos_enc = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (num_patches, hidden_dim),\n        trainable=True,\n    )\nvit_parameters['positional_encoding'] = pos_enc\n\n\n\nhead_params = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (hidden_dim, num_classes),\n        trainable=True,\n    )\nhead_bias = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (num_classes, ),\n        trainable=True,\n    )\nvit_parameters['head'] = (head_params, head_bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:17.408514Z","iopub.execute_input":"2025-11-08T16:24:17.408814Z","iopub.status.idle":"2025-11-08T16:24:28.880985Z","shell.execute_reply.started":"2025-11-08T16:24:17.408796Z","shell.execute_reply":"2025-11-08T16:24:28.879513Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1762619057.453588    2857 common_lib.cc:648] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:238\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def initialize_mlp(hidden_dim, mlp_dim):\n\n\n    w1 = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (hidden_dim, mlp_dim),\n        trainable=True,\n    )\n    b1 = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (mlp_dim, ),\n        trainable=True,\n    )\n\n    w2 = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (mlp_dim, hidden_dim),\n        trainable=True,\n    )\n    b2 = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (hidden_dim, ),\n        trainable=True,\n    )\n\n    return w1, b1, w2, b2\n\n\ndef initialize_attention(hidden_dim, num_heads):\n\n    fan_in = hidden_dim\n    fan_out = head_dim * num_heads\n\n\n    q_w = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (fan_in, fan_out),\n        trainable=True,\n    )\n    q_b = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (fan_out, ),\n        trainable=True,\n    )\n    \n    k_w = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (fan_in, fan_out),\n        trainable=True,\n    )\n    k_b = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (fan_out, ),\n        trainable=True,\n    )\n    \n    v_w = keras.Variable(\n        initializer=initializers.RandomNormal(stddev=0.01),\n        shape = (fan_in, fan_out),\n        trainable=True,\n    )\n    v_b = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (fan_out, ),\n        trainable=True,\n    )\n\n    return q_w, k_w, v_w, q_b, k_b, v_b\n\n\ndef initialize_layer_norm(hidden_dim):\n    gamma = keras.Variable(\n        initializer=initializers.Ones(),\n        shape = (hidden_dim, ),\n        trainable=True,\n    )\n    beta = keras.Variable(\n        initializer=initializers.Zeros(),\n        shape = (hidden_dim, ),\n        trainable=True,\n    )\n    return gamma, beta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:28.881789Z","iopub.execute_input":"2025-11-08T16:24:28.881982Z","iopub.status.idle":"2025-11-08T16:24:28.888359Z","shell.execute_reply.started":"2025-11-08T16:24:28.881965Z","shell.execute_reply":"2025-11-08T16:24:28.887476Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"for i in range(num_layers):\n    mlp_params = initialize_mlp(hidden_dim, mlp_dim)\n    attn_params = initialize_attention(hidden_dim, num_heads)\n    ln1_params = initialize_layer_norm(hidden_dim)\n    ln2_params = initialize_layer_norm(hidden_dim)\n    vit_parameters['layers'].append((mlp_params, attn_params, ln1_params, ln2_params))\n\n\n\nfinal_layer_norm_params = initialize_layer_norm(hidden_dim)\nvit_parameters['final_layer_norm'] = final_layer_norm_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:28.889058Z","iopub.execute_input":"2025-11-08T16:24:28.889220Z","iopub.status.idle":"2025-11-08T16:24:29.539080Z","shell.execute_reply.started":"2025-11-08T16:24:28.889205Z","shell.execute_reply":"2025-11-08T16:24:29.537775Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def relu(input):\n    return ops.maximum(0, input)\n\n\ndef softmax(x, axis=-1):\n    x_max = ops.max(x, axis=axis, keepdims=True)\n    x_shifted = x - x_max\n    exp_x = ops.exp(x_shifted)\n    return exp_x / ops.sum(exp_x, axis=axis, keepdims=True)\n\ndef mlp(x, mlp_params):\n\n    # unpack the parameters\n    w1, b1, w2, b2 = mlp_params\n\n    # out = (Relu(x*w1 + b1))*w2 + b2\n    up_proj = relu(ops.matmul(x, w1) + b1)\n    down_proj = ops.matmul(up_proj, w2) + b2\n\n    return down_proj\n\n\ndef self_attention(x, attn_params):\n\n    # unpack the parameters\n    q_w, k_w, v_w, q_b, k_b, v_b = attn_params\n\n    # n and d_k are the sequence length of the input and the hidden dimension\n    n, d_k = x.shape\n\n    # project the input into the query, key and value spaces\n    q = ops.matmul(x, q_w) + q_b\n    k = ops.matmul(x, k_w) + k_b\n    v = ops.matmul(x, v_w) + v_b\n\n\n    # reshape to have heads\n    # n, (num_heads head_dim) ->  (n, num_heads, headim) -> (num_heads, n, head_dim)\n    q = q.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n    k = k.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n    v = v.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n\n    # perform multi-head attention\n    attention_weights_heads = ops.matmul(q, ops.swapaxes(k, -1, -2)) / ops.sqrt(head_dim)\n    attention_weights_heads = ops.softmax(attention_weights_heads, axis=-1)\n\n    # output projection (num_heads, n, head_dim)\n    output = ops.matmul(attention_weights_heads, v)\n\n    # reshape back (n, num_heads * heam_dim)\n    output = output.swapaxes(0,1).reshape(n, d_k)\n\n    return output\n\n\ndef layer_norm(x, layernorm_params):\n    # a simple layer norm\n    gamma, beta = layernorm_params\n    mean = ops.mean(x, axis=-1, keepdims=True)\n    var = ops.var(x, axis=-1, keepdims=True)\n    return gamma * (x - mean) / ops.sqrt(var + 1e-6) + beta\n\n\ndef transformer_block(inp, block_params):\n\n    # unpack the parameters\n    mlp_params, attn_params, ln1_params, ln2_params = block_params\n\n    # attention\n    x = layer_norm(inp, ln1_params)\n    x = self_attention(x, attn_params)\n    skip = x + inp\n\n    # mlp\n    x = layer_norm(skip, ln2_params)\n    x = mlp(x, mlp_params)\n    x = x + skip\n\n    return x\n\n\ndef transformer(patches, vit_parameters):\n\n    # reshape image from c,h,w -> num_patches, patch_size*patch_size\n    patches = rearrange (patches, 'c (h p1) (w p2) -> (h w) (p1 p2 c)', p1=patch_size, p2=patch_size)\n\n    # embed the patches\n    patches = ops.matmul(patches, vit_parameters['patch_embed'])\n\n    # add positional encoding\n    patches = patches + vit_parameters['positional_encoding']\n\n    # append class token to sequence\n    cls_token = vit_parameters['cls_token']\n    patches = ops.concatenate([cls_token, patches], axis=0)\n\n\n    # forward through all transformer blocks\n    for layer, block_params in enumerate(vit_parameters['layers']):\n        patches = transformer_block(patches, block_params)\n\n    # final layer norm\n    patches = layer_norm(patches, vit_parameters['final_layer_norm'])\n\n    # get the class token and apply the final head\n    patches = patches[0, :]\n    logits = ops.matmul(patches, vit_parameters['head'][0]) + vit_parameters['head'][1]\n    return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:29.539929Z","iopub.execute_input":"2025-11-08T16:24:29.540119Z","iopub.status.idle":"2025-11-08T16:24:29.548381Z","shell.execute_reply.started":"2025-11-08T16:24:29.540102Z","shell.execute_reply":"2025-11-08T16:24:29.547426Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"key = random.PRNGKey(42)\n\nsample_image = random.normal(key, (3 ,image_size, image_size))\nprediction = transformer(sample_image, vit_parameters)\nprint(\"Output shape:\", prediction.shape) # should be (num_classes,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:29.548798Z","iopub.execute_input":"2025-11-08T16:24:29.548966Z","iopub.status.idle":"2025-11-08T16:24:31.851024Z","shell.execute_reply.started":"2025-11-08T16:24:29.548950Z","shell.execute_reply":"2025-11-08T16:24:31.849772Z"}},"outputs":[{"name":"stdout","text":"Output shape: (10,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"bsize = 5\nsample_images = random.normal(key, (bsize, 3 ,image_size, image_size))\n\nprediction = jax.vmap(transformer, in_axes=(0, None))(sample_images, vit_parameters)\nprint(\"Prediction shape:\", prediction.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:31.851991Z","iopub.execute_input":"2025-11-08T16:24:31.852180Z","iopub.status.idle":"2025-11-08T16:24:35.269538Z","shell.execute_reply.started":"2025-11-08T16:24:31.852162Z","shell.execute_reply":"2025-11-08T16:24:35.268395Z"}},"outputs":[{"name":"stdout","text":"Prediction shape: (5, 10)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def cross_entropy_loss(patches, vit_parameters, ground_truth):\n    prediction = jax.vmap(transformer, in_axes=(0, None))(patches, vit_parameters)\n    logs = ops.log_softmax(prediction)\n    l = -ops.mean(ops.sum(ground_truth * logs, axis=-1))\n    return l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:35.270065Z","iopub.execute_input":"2025-11-08T16:24:35.270261Z","iopub.status.idle":"2025-11-08T16:24:35.274039Z","shell.execute_reply.started":"2025-11-08T16:24:35.270244Z","shell.execute_reply":"2025-11-08T16:24:35.273111Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"l = cross_entropy_loss(sample_images, vit_parameters, jnp.zeros((bsize, 10)).at[0, 1].set(1))\nprint(\"Loss:\", l)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:35.274796Z","iopub.execute_input":"2025-11-08T16:24:35.274958Z","iopub.status.idle":"2025-11-08T16:24:35.626914Z","shell.execute_reply.started":"2025-11-08T16:24:35.274944Z","shell.execute_reply":"2025-11-08T16:24:35.625717Z"}},"outputs":[{"name":"stdout","text":"Loss: 0.453823\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n\n\ntrain_dataset = Imagenette(\n    root='imagenette3',\n    size=\"160px\",\n    split='train',\n    download=True,\n    transform=transforms.Compose([transforms.Resize((image_size,image_size)),  transforms.ToTensor(), transforms.Normalize(mean, std)])\n    )\ntrain_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n\n\ntest_dataset = Imagenette(\n    root='imagenette3',\n    size=\"160px\",\n    split='val',\n    download=True,\n    transform=transforms.Compose([transforms.Resize((image_size,image_size)), transforms.ToTensor(), transforms.Normalize(mean, std)])\n    )\ntest_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:35.627422Z","iopub.execute_input":"2025-11-08T16:24:35.627607Z","iopub.status.idle":"2025-11-08T16:24:35.656973Z","shell.execute_reply.started":"2025-11-08T16:24:35.627591Z","shell.execute_reply":"2025-11-08T16:24:35.655916Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def eval(vit_parameters):\n\n  correct = 0\n\n  for(img, target) in tqdm(test_loader, desc=\"Eval\", unit=\"item\"):\n\n    img = jnp.asarray(img, dtype=jnp.float32)\n    target = jnp.asarray(target)\n\n    logits = jax.vmap(transformer, in_axes=(0, None))(img, vit_parameters)\n    prediction = jnp.argmax(logits, axis=-1)\n    correct += jnp.sum(prediction == target).item()\n\n\n  acc = correct / len(test_dataset)\n\n  return acc\n\naccuracy = eval(vit_parameters)\nprint(\"Accuracy before training\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:24:36.978819Z","iopub.execute_input":"2025-11-08T16:24:36.979155Z","iopub.status.idle":"2025-11-08T16:25:02.729907Z","shell.execute_reply.started":"2025-11-08T16:24:36.979125Z","shell.execute_reply":"2025-11-08T16:25:02.728933Z"}},"outputs":[{"name":"stderr","text":"Eval: 100%|██████████| 16/16 [00:25<00:00,  1.61s/item]","output_type":"stream"},{"name":"stdout","text":"Accuracy before training 0.11923566878980892\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# fake labels and images\nsample_images = random.normal(key, (bsize, 3 ,image_size, image_size))\nsample_target = jnp.zeros((bsize, 10)).at[0, 1].set(1)\ncurrent_loss, grads = value_and_grad(cross_entropy_loss, argnums=1)(sample_images, vit_parameters, sample_target)\n\nprint(\"Current loss:\", current_loss)\nprint(\"Gradients:\", grads.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:25:38.949353Z","iopub.execute_input":"2025-11-08T16:25:38.949607Z","iopub.status.idle":"2025-11-08T16:25:39.456290Z","shell.execute_reply.started":"2025-11-08T16:25:38.949589Z","shell.execute_reply":"2025-11-08T16:25:39.455226Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_2857/1947696068.py:88: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  patches = ops.matmul(patches, vit_parameters['patch_embed'])\n/tmp/ipykernel_2857/1947696068.py:91: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  patches = patches + vit_parameters['positional_encoding']\n/tmp/ipykernel_2857/1947696068.py:100: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  patches = transformer_block(patches, block_params)\n/tmp/ipykernel_2857/1947696068.py:61: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  return gamma * (x - mean) / ops.sqrt(var + 1e-6) + beta\n/tmp/ipykernel_2857/1947696068.py:32: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  q = ops.matmul(x, q_w) + q_b\n/tmp/ipykernel_2857/1947696068.py:33: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  k = ops.matmul(x, k_w) + k_b\n/tmp/ipykernel_2857/1947696068.py:34: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  v = ops.matmul(x, v_w) + v_b\n/tmp/ipykernel_2857/1947696068.py:17: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  up_proj = relu(ops.matmul(x, w1) + b1)\n/tmp/ipykernel_2857/1947696068.py:18: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  down_proj = ops.matmul(up_proj, w2) + b2\n","output_type":"stream"},{"name":"stdout","text":"Current loss: 0.453823\nGradients: dict_keys(['cls_token', 'final_layer_norm', 'head', 'layers', 'patch_embed', 'positional_encoding'])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_2857/1947696068.py:107: DeprecationWarning: Triggering of __jax_array__() during abstractification is deprecated. To avoid this error, either explicitly convert your object using jax.numpy.array(), or register your object as a pytree.\n  logits = ops.matmul(patches, vit_parameters['head'][0]) + vit_parameters['head'][1]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"@jit\ndef train_step(patches, vit_parameters, target):\n    # compute gradients\n    current_loss, grads = value_and_grad(cross_entropy_loss, argnums=1)(\n        patches,\n        vit_parameters,\n        target)\n\n    # update parameters\n    updated_params = jax.tree.map(lambda p, g: p - 0.01 * g, vit_parameters, grads)\n\n    return current_loss, updated_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:25:53.539298Z","iopub.execute_input":"2025-11-08T16:25:53.539668Z","iopub.status.idle":"2025-11-08T16:25:53.543565Z","shell.execute_reply.started":"2025-11-08T16:25:53.539634Z","shell.execute_reply":"2025-11-08T16:25:53.542634Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"num_epochs = 20\n\n\nfor epoch in range(num_epochs):\n\n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    #for (data, target) in tqdm(train_loader, desc=f'Train epoch {epoch}'):\n    for i, (data, target) in progress_bar:\n\n        # convert to numpy\n        data = jnp.asarray(data)\n        target = jnp.asarray(target)\n\n        # reshape and get one hot fot loss\n        target_one_hot = jax.nn.one_hot(target, num_classes)\n\n        current_loss, vit_parameters = train_step(data, vit_parameters, target_one_hot)\n\n        progress_bar.set_postfix({'loss': current_loss})\n\n\n    eval_acc = eval(vit_parameters)\n    print(f'Epoch: {epoch}, Eval acc: {eval_acc}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T16:26:05.778388Z","iopub.execute_input":"2025-11-08T16:26:05.778855Z","iopub.status.idle":"2025-11-08T16:38:28.537706Z","shell.execute_reply.started":"2025-11-08T16:26:05.778750Z","shell.execute_reply":"2025-11-08T16:38:28.536557Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 37/37 [00:33<00:00,  1.09it/s, loss=2.120179] \nEval: 100%|██████████| 16/16 [00:13<00:00,  1.16item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Eval acc: 0.21987261146496814\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 37/37 [00:22<00:00,  1.67it/s, loss=2.1085021]\nEval: 100%|██████████| 16/16 [00:13<00:00,  1.18item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Eval acc: 0.2575796178343949\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 37/37 [00:22<00:00,  1.63it/s, loss=2.029838] \nEval: 100%|██████████| 16/16 [00:13<00:00,  1.17item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Eval acc: 0.24764331210191082\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 37/37 [00:22<00:00,  1.62it/s, loss=1.9859735]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.14item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Eval acc: 0.2540127388535032\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 37/37 [00:22<00:00,  1.67it/s, loss=1.9744337]\nEval: 100%|██████████| 16/16 [00:15<00:00,  1.00item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Eval acc: 0.2761783439490446\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 37/37 [00:22<00:00,  1.67it/s, loss=1.9847224]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.12item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Eval acc: 0.3029299363057325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 37/37 [00:21<00:00,  1.70it/s, loss=1.9853494]\nEval: 100%|██████████| 16/16 [00:15<00:00,  1.05item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Eval acc: 0.2968152866242038\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 37/37 [00:22<00:00,  1.66it/s, loss=1.9634247]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.11item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7, Eval acc: 0.3080254777070064\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 37/37 [00:21<00:00,  1.70it/s, loss=1.908057] \nEval: 100%|██████████| 16/16 [00:13<00:00,  1.20item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8, Eval acc: 0.27694267515923565\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 37/37 [00:22<00:00,  1.65it/s, loss=1.9818041]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.08item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9, Eval acc: 0.255031847133758\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 37/37 [00:22<00:00,  1.68it/s, loss=1.9826884]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.11item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Eval acc: 0.30369426751592354\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 37/37 [00:22<00:00,  1.66it/s, loss=1.9982338]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.12item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11, Eval acc: 0.30522292993630573\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|██████████| 37/37 [00:22<00:00,  1.63it/s, loss=1.897428] \nEval: 100%|██████████| 16/16 [00:14<00:00,  1.09item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12, Eval acc: 0.3154140127388535\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|██████████| 37/37 [00:21<00:00,  1.69it/s, loss=1.8940327]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.14item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13, Eval acc: 0.3159235668789809\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|██████████| 37/37 [00:22<00:00,  1.66it/s, loss=1.9319364]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.08item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14, Eval acc: 0.3189808917197452\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|██████████| 37/37 [00:21<00:00,  1.69it/s, loss=1.8812433]\nEval: 100%|██████████| 16/16 [00:13<00:00,  1.16item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15, Eval acc: 0.32764331210191083\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|██████████| 37/37 [00:22<00:00,  1.67it/s, loss=1.9737448]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.09item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16, Eval acc: 0.3057324840764331\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|██████████| 37/37 [00:22<00:00,  1.68it/s, loss=1.9212428]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.11item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17, Eval acc: 0.31414012738853503\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|██████████| 37/37 [00:21<00:00,  1.69it/s, loss=1.84732]  \nEval: 100%|██████████| 16/16 [00:13<00:00,  1.15item/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18, Eval acc: 0.32178343949044586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|██████████| 37/37 [00:22<00:00,  1.67it/s, loss=2.0011415]\nEval: 100%|██████████| 16/16 [00:14<00:00,  1.10item/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 19, Eval acc: 0.3131210191082803\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17}]}